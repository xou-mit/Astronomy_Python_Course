{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2a9f6b",
   "metadata": {},
   "source": [
    "# Binary Star Fitting: Curve Fit (Cont.)\n",
    "\n",
    "Continuing last week's exercise with fitting the binary star systems velocity variation, we now explore the power of emcee as a more efficient approach to sample the possible solution space. We'll explore:\n",
    "\n",
    "1. **Theoretical Background**: What does emcee do differently from scipy curvefit\n",
    "2. **Curve Fitting**: Using `emcee` in action and examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8737919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import emcee\n",
    "import corner\n",
    "from astropy import units as u\n",
    "from astropy.constants import G\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1057d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the data\n",
    "url = \"https://drive.google.com/uc?export=download&id=1hmYypOQxt7ZJ1-JxYurqU7tnsNGBMMDj\" #binary_measurements_observed.csv file\n",
    "binary_data_inc = pd.read_csv(url)\n",
    "# binary_data_inc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = binary_data_inc['time']\n",
    "v_r_obs = binary_data_inc['vlos']\n",
    "sigma_obs_array = binary_data_inc['error']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c0072",
   "metadata": {},
   "source": [
    "## 2. Bayesian Analysis with emcee\n",
    "\n",
    "Now let's use `emcee` to perform a Bayesian analysis. This will explore the entire parameter space and reveal all possible solutions, not just the local minimum found by `curve_fit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abf314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models for calculating the radial velocities of stars\n",
    "def solve_kepler_equation(E, e):\n",
    "    \"\"\"Solve Kepler's equation: M = E - e*sin(E)\"\"\"\n",
    "    M = E - e * np.sin(E)\n",
    "    return M\n",
    "\n",
    "def get_true_anomaly(E, e):\n",
    "    \"\"\"Calculate true anomaly from eccentric anomaly\"\"\"\n",
    "    f = 2 * np.arctan(np.sqrt((1 + e) / (1 - e)) * np.tan(E / 2))\n",
    "    return f\n",
    "\n",
    "def radial_velocity_model(t, P, e, omega, T0, K, gamma):\n",
    "    \"\"\"\n",
    "    Calculate radial velocity for a binary star system\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    t : array_like\n",
    "        Time array\n",
    "    P : float\n",
    "        Orbital period in days\n",
    "    e : float\n",
    "        Eccentricity (0-1)\n",
    "    omega : float\n",
    "        Argument of periastron in radians\n",
    "    T0 : float\n",
    "        Time of periastron passage\n",
    "    K : float\n",
    "        Velocity amplitude in km/s\n",
    "    gamma : float\n",
    "        Systemic velocity in km/s\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    v_r : array_like\n",
    "        Radial velocity in km/s\n",
    "    \"\"\"\n",
    "    # Mean anomaly\n",
    "    M = 2 * np.pi * (t - T0) / P\n",
    "    \n",
    "    # Solve for eccentric anomaly using Newton-Raphson\n",
    "    E = M.copy()  # Initial guess\n",
    "    for _ in range(10):  # Max iterations\n",
    "        E_new = E - (E - e * np.sin(E) - M) / (1 - e * np.cos(E))\n",
    "        if np.allclose(E, E_new, rtol=1e-10):\n",
    "            break\n",
    "        E = E_new\n",
    "    \n",
    "    # True anomaly\n",
    "    f = get_true_anomaly(E, e)\n",
    "    \n",
    "    # Radial velocity\n",
    "    v_r = gamma + K * (np.cos(omega + f) + e * np.cos(omega))\n",
    "    \n",
    "    return v_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log-likelihood function\n",
    "def log_likelihood(theta, t, v_r, sigma):\n",
    "    \"\"\"\n",
    "    Log-likelihood function for the radial velocity model\n",
    "    \"\"\"\n",
    "    P, e, omega, T0, K, gamma = theta\n",
    "    \n",
    "    # Calculate model predictions\n",
    "    v_r_model = radial_velocity_model(t, P, e, omega, T0, K, gamma)\n",
    "    \n",
    "    # Calculate log-likelihood (assuming Gaussian errors)\n",
    "    log_like = -0.5 * np.sum(((v_r - v_r_model) / sigma)**2 + np.log(2 * np.pi * sigma**2))\n",
    "    \n",
    "    return log_like\n",
    "\n",
    "# Define the log-prior function\n",
    "def log_prior(theta):\n",
    "    \"\"\"\n",
    "    Log-prior function with broad, uninformative priors\n",
    "    \"\"\"\n",
    "    P, e, omega, T0, K, gamma = theta\n",
    "    \n",
    "    # Broad priors\n",
    "    if (10 < P < 500 and \n",
    "        0 < e < 0.99 and \n",
    "        0 < omega < 2*np.pi and \n",
    "        0 < T0 < 100 and \n",
    "        5 < K < 50 and \n",
    "        -100 < gamma < 100):\n",
    "        return 0.0  # Uniform prior\n",
    "    \n",
    "    return -np.inf  # Outside prior range\n",
    "\n",
    "\n",
    "# Define the log-posterior function\n",
    "def log_posterior(theta, t, v_r, sigma):\n",
    "    \"\"\"\n",
    "    Log-posterior function\n",
    "    \"\"\"\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    return lp + log_likelihood(theta, t, v_r, sigma)\n",
    "\n",
    "# Set up the MCMC sampler\n",
    "nwalkers = 50  # Number of walkers\n",
    "ndim = 6       # Number of parameters\n",
    "nsteps = 2000  # Number of steps\n",
    "\n",
    "# Initial positions for walkers (scattered around the parameter space)\n",
    "initial_positions = np.array([\n",
    "    np.random.uniform(20, 490, nwalkers),      # P\n",
    "    np.random.uniform(0.1, 0.8, nwalkers),     # e\n",
    "    np.random.uniform(0, 2*np.pi, nwalkers),   # omega\n",
    "    np.random.uniform(0, 80, nwalkers),        # T0\n",
    "    np.random.uniform(10, 40, nwalkers),       # K\n",
    "    np.random.uniform(-90, 90, nwalkers)       # gamma\n",
    "]).T\n",
    "\n",
    "print(f\"Setting up MCMC with {nwalkers} walkers, {nsteps} steps\")\n",
    "print(f\"Initial positions spread across parameter space\")\n",
    "\n",
    "# Create the sampler\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, ndim, log_posterior, \n",
    "    args=(t_obs, v_r_obs, sigma_obs_array)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MCMC\n",
    "print(\"Running MCMC...\")\n",
    "sampler.run_mcmc(initial_positions, nsteps, progress=True)\n",
    "\n",
    "# Get the samples (discard burn-in)\n",
    "burn_in = 500\n",
    "samples = sampler.get_chain(discard=burn_in, flat=True)\n",
    "\n",
    "print(f\"\\nMCMC completed!\")\n",
    "print(f\"Discarded {burn_in} steps as burn-in\")\n",
    "print(f\"Final sample size: {len(samples)} points\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate acceptance fraction\n",
    "acceptance_fraction = np.mean(sampler.acceptance_fraction)\n",
    "print(f\"Average acceptance fraction: {acceptance_fraction:.3f}\")\n",
    "\n",
    "# Plot the chain evolution\n",
    "fig, axes = plt.subplots(ndim, 1, figsize=(12, 10), sharex=True)\n",
    "for i, param_name in enumerate(param_names):\n",
    "    axes[i].plot(sampler.get_chain()[:, :, i], alpha=0.3)\n",
    "    axes[i].axvline(burn_in, color='r', linestyle='--', alpha=0.7)\n",
    "    axes[i].set_ylabel(param_name)\n",
    "    if i == ndim - 1:\n",
    "        axes[i].set_xlabel('Step')\n",
    "\n",
    "plt.suptitle('MCMC Chain Evolution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25527d27",
   "metadata": {},
   "source": [
    "## 2.1 Analyze the Posterior Distribution\n",
    "\n",
    "Now let's analyze the posterior distribution to see what the Bayesian analysis reveals about the parameter space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a883e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "param_medians = np.median(samples, axis=0)\n",
    "param_errors = np.std(samples, axis=0)\n",
    "param_16th = np.percentile(samples, 16, axis=0)\n",
    "param_84th = np.percentile(samples, 84, axis=0)\n",
    "\n",
    "print(\"Bayesian Analysis Results:\")\n",
    "print(\"Parameter | Median | 16th %ile | 84th %ile\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    median_val = param_medians[i]\n",
    "    low_val = param_16th[i]\n",
    "    high_val = param_84th[i]\n",
    "    \n",
    "    if name == 'omega':\n",
    "        print(f\"{name:8s} | {median_val:6.3f} | {low_val:8.3f} | {high_val:8.3f}\")\n",
    "    else:\n",
    "        print(f\"{name:8s} | {median_val:6.3f} | {low_val:8.3f} | {high_val:8.3f}\")\n",
    "\n",
    "# Create corner plot\n",
    "fig = corner.corner(\n",
    "    samples, \n",
    "    labels=param_names,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 12}\n",
    ")\n",
    "\n",
    "plt.suptitle('Posterior Distribution', fontsize=16)\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ae417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot individual parameter distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, name in enumerate(param_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histogram of samples\n",
    "    ax.hist(samples[:, i], bins=50, alpha=0.7, density=True, color='skyblue')\n",
    "    \n",
    "    # Median and confidence intervals\n",
    "    ax.axvline(param_medians[i], color='black', linestyle='-', linewidth=2, \n",
    "               label='Median')\n",
    "    ax.axvline(param_16th[i], color='black', linestyle=':', alpha=0.7)\n",
    "    ax.axvline(param_84th[i], color='black', linestyle=':', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{name} Posterior Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ee6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of distinct solutions\n",
    "print(\"\\nAnalyzing posterior for multiple solutions...\")\n",
    "\n",
    "# Look for bimodal distributions (especially in omega)\n",
    "omega_samples = samples[:, 2]  # omega parameter\n",
    "omega_hist, omega_bins = np.histogram(omega_samples, bins=100)\n",
    "omega_centers = (omega_bins[:-1] + omega_bins[1:]) / 2\n",
    "\n",
    "# Find peaks in the omega distribution\n",
    "from scipy.signal import find_peaks\n",
    "peaks, _ = find_peaks(omega_hist, height=np.max(omega_hist)*0.1, distance=10)\n",
    "\n",
    "print(f\"Found {len(peaks)} peaks in omega distribution\")\n",
    "for i, peak in enumerate(peaks):\n",
    "    peak_omega = omega_centers[peak]\n",
    "    print(f\"Peak {i+1}: omega = {peak_omega:.3f} rad ({np.degrees(peak_omega):.1f}°)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9f24d",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "1. **Incomplete Data Challenges**: When observations are sparse or incomplete, multiple solutions can fit the data equally well. This is a common problem in astronomy.\n",
    "\n",
    "2. **Initial Guess Sensitivity**: The `curve_fit` method is sensitive to initial parameter guesses. With incomplete data, different starting points can lead to different (but equally valid) solutions.\n",
    "\n",
    "3. **Bayesian Advantages**: The `emcee` approach explores the entire parameter space and reveals all possible solutions, not just local minima.\n",
    "\n",
    "4. **Uncertainty Quantification**: Bayesian methods provide proper uncertainty estimates that account for parameter correlations and degeneracies.\n",
    "\n",
    "5. **Prior Information**: The choice of priors in Bayesian analysis can significantly influence results, especially with limited data.\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Exoplanet Detection**: Radial velocity surveys often have incomplete phase coverage\n",
    "- **Binary Star Studies**: Limited observing windows due to weather, telescope scheduling\n",
    "- **Asteroid Orbits**: Sparse observations over long time periods\n",
    "- **Galaxy Dynamics**: Limited spatial coverage in velocity field measurements\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Always check multiple initial guesses** when using optimization methods\n",
    "2. **Use Bayesian methods** when dealing with incomplete or sparse data\n",
    "3. **Consider parameter degeneracies** and their physical implications\n",
    "4. **Plan observations** to break degeneracies when possible\n",
    "5. **Report uncertainties** that reflect the true parameter space\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
